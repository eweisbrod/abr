[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Business Research",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a work in process website for a potential book on applied business research in R. The goal of the website is to provide tools and examples for reproducible and well-formatted research reports.\nThis is an example of a Quarto citation Knuth (1984) in a sentence.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "project-setup.html",
    "href": "project-setup.html",
    "title": "2  Project Setup",
    "section": "",
    "text": "2.1 Git vs. GitHub\nGit is the underlying code that helps manage version control of your projects. You can find more information about the details of Git here. Information about how to install git on your machine can be found here.\nGitHub is a web-based user interface that makes Git easier to work with by allowing “point-and-click” version control rather than typing git commands. You will want to set up a GitHub account. The rest of this chapter will reference the use of GitHub, although everything discussed can also be accomplished through the Git language.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Setup</span>"
    ]
  },
  {
    "objectID": "project-setup.html#language-of-github",
    "href": "project-setup.html#language-of-github",
    "title": "2  Project Setup",
    "section": "2.2 Language of GitHub",
    "text": "2.2 Language of GitHub\nIt is important to remember that GitHub acts as a version control interface for your research projects. So, while we will discuss the verbiage of GitHub, at its core, all that it is doing is keeping track of the changes that you make to your code. It may be helpful to translate the Git language into words you regularly associate with project management.\nRepository - A repository is where all the code for a specific project lives. You can think of it like the project folder where your code is stored. The benefit of a repository is that it is stored online, allowing you to easily access it from any machine. You will most likely want to make your repository private, so that only you and people you identify as co-authors can access your code.\nFork - “Forking” a repository is equivalent to making a copy of someone else’s repository. If a repository is made public, then anyone can fork the repository to have their own copy. This is unlikely to be something that will commonly occur in your own research, as we will discuss next. You can think of forking a repository as the same as copying someone else’s code folder and pasting it onto your computer.\nClone - “Cloning” is where the power of GitHub really begins. Cloning a repository is the same as giving your local machine (e.g., computer) access to the code in the repository. Think of it like installing Dropbox on another computer. Now you have access to all the files stored on Dropbox. Cloning a repository is the exact same thing for code. Once you have cloned the repository, you can now work on the code from that machine. The power comes in by being able to clone the repository on multiple computers, and your coauthors doing the same, allowing you all to work on the same set of code. To clone a repository, you will need the cloning URL. To get this, go to the repository on GitHub, click the green “Code” button, and click on the copy button (two intersecting squares) next to the HTTPS URL.\nStaging - Once you save the code you are working on to your local computer, a new row will appear under the “Git” tab in the top right panel of R Studio. In order to officially “save” your changes to your online GitHub repository, you need to first stage the changes. “Staging” is the same thing as “selecting” which changes you want to officially send to GitHub, which will be discussed next.\nCommit - Once you have staged your changes, you are ready to begin the process of uploading them to GitHub. The first thing you need to do is to “commit” the changes. As the name implies, a “commit” means you are committed ;) to making the changes to the code. To do this, click the “Commit” button in the top right panel of R Studio. You will need to type a short message which summarizes the changes that you have made, which will be visible on GitHub so you can easily see the evolution of your code over time. Once you have typed your message, click “Commit”.\nPull - “Pulling” is effectively the same as downloading the most recent version of your project’s code onto your local computer. When you click “Pull” in the top right panel of R Studio, you are “pulling” the code from GitHub onto your local machine. You should always pull before you push!\nPush - “Pushing” is the final step of saving your code through GitHub. After you have committed your changes and pulled the most recent version of the project to your machine, you can send your changes to GitHub by clicking “Push” in the top right panel of R Studio. Doing this officially sends the changes that you have made up to GitHub, effectively pushing the code from your local device onto GitHub. This can also be thought of as if you made changes to a file on your local computer and then saved that file onto Dropbox. The power of GitHub is that you can see both the old version and new version, and restore your code to older versions if you decide you don’t like your changes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Setup</span>"
    ]
  },
  {
    "objectID": "project-setup.html#power-of-projects",
    "href": "project-setup.html#power-of-projects",
    "title": "2  Project Setup",
    "section": "2.3 Power of Projects",
    "text": "2.3 Power of Projects\nWhen you first begin working with R, one of the first things that you learn are the benefits of storing/saving code in R scripts. In theory, we could always write all of our code in the terminal, and just rewrite it every time we wanted to run a command (gross!). Using R scripts allows us to save our code, which can be run the exact same way every time. In a nutshell, what the R script is really doing is making our code more reproducible, as we can be sure that we are always running the same commands.\nThe next evolution of your R journey probably went something like this… You realized that trying to code up an entire research project in one R script was burdensome. There are thousands of lines of code, some of which you do not want to run every time. So, you break up your project into multiple R scripts, with each one serving a different function (e.g., data download, data cleaning, analysis, figures, etc.). While this likely initially occurred just by saving the different scripts in the Dropbox folder where you stored your project files (code, data, paper drafts, etc.), we will next discuss how we can integrate GitHub to help make working on a research project easier.\nProjects in R can be thought of as self-contained folders, where all your code and associated documents can live. The power of these projects is that they can be integrated with GitHub, making your work more reproducible by keeping all your code for a project in one place along with the version history.1 To start a new project, you will first create a repository on GitHub with this project’s name. You then go into R Studio and click “File -&gt; New Project”. From there, you will click on “Version Control -&gt; Git”. This brings you to a screen which will allow you to clone (see above if this is unfamiliar) your GitHub repository to your local machine. You will copy and paste the URL from the repository into the “Repository URL” text box. The “Project directory name:” box will populate with a location on your local computer. This is where the project and subsequent R scripts will live. How you manage these comes down to personal preference, but a common way to store GitHub projects locally is to create a “git” folder on your computer’s C-drive and then store each project in the git folder. Once you have set the project directory, you can select “Create Project” to create the local version of the repository on your computer.\nThe key thing to notice (and one of the many powers of working within projects) is located near the top right corner of R Studio. You will now see a blue box with the letter “R” inside of it, which is the image of an R project. Next to this, you will see the name of the project you just created, indicating that you are working “inside” this project. When you look at the “Files” in the bottom right panel, you will see that the directory has been changed to the location of your R project. This allows you to see all the scripts associated with this project, and quickly change between scripts. Importantly, any pushes that you make to GitHub will be pushed to that specific project.\nOne of the nice features of working in projects is the ability to quickly access your project code and switch between projects. For example, if you were conducting a research project using just R scripts, you would need to save them somewhere (e.g., Dropbox) and navigate to that folder to open/access them. When using an R project, rather than navigating to the folder on your computer that contains your code, you can just open R Studio and click on the R project button in the top right corner (blue cube with “R” inside). This will open up a drop down menu of all the projects you have on your computer, allowing you to open the one you want. When you close the project, whatever R scripts that you have open at the time you close will automatically open again the next time you open the project.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Setup</span>"
    ]
  },
  {
    "objectID": "project-setup.html#reproducible-workflow",
    "href": "project-setup.html#reproducible-workflow",
    "title": "2  Project Setup",
    "section": "2.4 Reproducible Workflow",
    "text": "2.4 Reproducible Workflow\nAll of the things we have discussed up to this point have been about making our code and research projects more reproducible and easier to understand. Beyond these tools, it is important to remember that a truly reproducible research project means that someone can take your project and with limited/no prior knowledge about what you were doing, replicate your findings and understand your code. To make this possible, it is important to try and make your code as clear and concise as possible, including plenty of documentation and comments in the code explaining what is happening. One of the best ways that I have found to keep my workflow easy to track is through developing a consistent naming convention between R scripts and data files.\nWhen creating my R scripts, I always begin the script name with a number, beginning with “00”. This is then followed by “-short-description.R” where the “short-description” is a short description of what the code is doing. The scripts are numbered based on when in the sequence they should be run. So, you would run the “00” scripts first, then “01”, “02”, and so on. Importantly, any data that I save from a script is named beginning with that script’s numeric identifier. For example, if I save a data set called “new_data.parquet” from an R script titled “02-create-new-data.R”, then I would save the parquet file with the name “02_new_data.parquet” in my Dropbox data folder. Doing this helps along two dimensions. First, it makes your data folder much more organized, with the data ordered in the chronological order that it was generated by your code. Second (and most importantly) it makes it immediately obvious which script generated the data set. That way, if someone has questions about a particular data set, you can immediately know what R script generated the data.\nBelow is an example project setup with the naming convention. The first level of bullet points are the R scripts (which would be located in the git folder) and the second level are the data sets (which would be saved on Dropbox).\n\n00-Global-Parameters.R\n01-Download-WRDS-Data.R\n\n01_compustat_data_raw.parquet\n\n02-Create-Master-Data.R\n\n02_master_data.parquet\n\n03-Main-Analyses.R\n\n03.01_table_1.tex\n03.02_table_2.tex\n\n04-Figures.R\n\n04.01_figure_1.jpeg\n04.02_figure_2.jpeg",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Setup</span>"
    ]
  },
  {
    "objectID": "project-setup.html#footnotes",
    "href": "project-setup.html#footnotes",
    "title": "2  Project Setup",
    "section": "",
    "text": "Projects and repositories are linked together. A project lives in R and is an R object, while a repository lives on GitHub. When you read “repository” think “project” or vice versa, however you prefer.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Setup</span>"
    ]
  },
  {
    "objectID": "obtain-data.html",
    "href": "obtain-data.html",
    "title": "3  Obtaining and Merging Data",
    "section": "",
    "text": "This is my first time working on a Quarto book. So, this first post will be very rough for now. I will try to provide a few different examples of ways to obtain and merge data in R, and a few tips of things to keep in mind.\nWe already know how to obtain data from WRDS. Let’s use this to obtain some returns for the S&P 500. We could use the formal index data, but let’s take a shortcut and just use the popular SPY ETF that tracks the S&P 500. To do this, we need to find the CRSP identifier (PERMNO) for the ticker “SPY.” We can look in the WRDS stocknames file for this, and then use the SPY PERMNO to pull data from the CRSP monthly stock file.\n\n# Load Libraries [i.e., packages]\nlibrary(dbplyr)\nlibrary(RPostgres)\nlibrary(DBI)\nlibrary(glue)\nlibrary(arrow)\nlibrary(haven)\nlibrary(tictoc) #very optional timer, mostly as a teaching example\nlibrary(tidyverse) # I like to load tidyverse last to avoid package conflicts\n\n#I have done this in a separate chunk with the options\n# results: FALSE \n# message: FALSE\n#because I don't need to see the messages from loading the packages. \n\n\n# Log in to WRDS -------------------------------------------------------------------\n\n#before running this block, I used these commands to securely store my WRDS username and password:\n# keyring::key_set(\"WRDS_user\")\n# keyring::key_set(\"WRDS_pw\")\n\nif(exists(\"wrds\")){\n  dbDisconnect(wrds)  # because otherwise WRDS might time out\n}\n\nwrds &lt;- dbConnect(Postgres(),\n                  host='wrds-pgdata.wharton.upenn.edu',\n                  port=9737,\n                  user=keyring::key_get(\"WRDS_user\"),\n                  password=keyring::key_get(\"WRDS_pw\"),\n                  sslmode='require',\n                  dbname='wrds')\n\n\n# Create WRDS Table References -------------------------------------------------\ncrsp.msf &lt;- tbl(wrds,in_schema(\"crsp\",\"msf\"))\nstocknames &lt;- tbl(wrds,in_schema(\"crsp\",\"stocknames\"))\n\n#I am collecting this data locally to play with duplicates\nspy_permnos &lt;- stocknames |&gt; filter(ticker == \"SPY\") |&gt; collect() \n\nNotice that there are six observations in the stocknames table that all share the same ticker “SPY.” I am going to use this as a toy example to play with duplicates. My goal is for this data to be unique at the level of ticker-permno links. First, I can check whether this is true.\n\n#check whether there are duplicates \n#this simple logic is useful in general\n#group by the level I want to make unique,\n#count within each group\n#sort by descending count so that if there are duplicates\n#they will show up at the top. \nspy_permnos |&gt; \n  group_by(ticker,permno) |&gt; \n  count() |&gt; \n  arrange(-n)\n\n# A tibble: 3 × 3\n# Groups:   ticker, permno [3]\n  ticker permno     n\n  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n1 SPY     84398     3\n2 SPY     33910     1\n3 SPY     60716     1\n\n\nThere are multiple permnos connected to the SPY ticker and some duplicate entries for permno 84398 so I better just look at the data. Also this tells me that there are only a few rows so it doesn’t hurt to just print the data.\n\n#| #note that we can use the kable commmand to embed a simple table in the quarto document\nknitr::kable(spy_permnos)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npermno\nnamedt\nnameenddt\nshrcd\nexchcd\nsiccd\nncusip\nticker\ncomnam\nshrcls\npermco\nhexcd\ncusip\nst_date\nend_date\nnamedum\n\n\n\n\n33910\n1962-07-02\n1966-05-24\n10\n2\n2893\nNA\nSPY\nSPEEDRY CHEMICAL PRODS INC\nA\n2751\n3\n55914210\n1962-07-02\n1979-01-22\n2\n\n\n60716\n1978-10-03\n1987-07-01\n10\n1\n3811\n84756710\nSPY\nSPECTRA PHYSICS INC\nNA\n4215\n1\n84756710\n1972-12-14\n1987-07-01\n2\n\n\n84398\n1993-01-29\n2009-02-23\n73\n2\n6726\n78462F10\nSPY\nSPDR TRUST\nNA\n46699\n4\n78462F10\n1993-01-29\n2024-12-31\n2\n\n\n84398\n2009-02-24\n2010-01-26\n73\n4\n6726\n78462F10\nSPY\nSPDR TRUST\nNA\n46699\n4\n78462F10\n1993-01-29\n2024-12-31\n2\n\n\n84398\n2010-01-27\n2024-12-31\n73\n4\n6726\n78462F10\nSPY\nSPDR S & P 500 E T F TRUST\nNA\n46699\n4\n78462F10\n1993-01-29\n2024-12-31\n2\n\n\n\n\n\nLooking at the data, the company name for permno 84398 matches the SPDR S&P 500 ETF I am looking for. It looks like the duplicate entries might have to do with a change in the listing exchange for the ETF (exchcd) and then a slight name change in 2010 to make the name of the trust more descriptive. Let’s keep using this toy example to demonstrate some other functions for dealing with duplicates:\n\n#if I want to just collapse the duplicates, I can use \"distinct\" across the groups that I care about\n\nspy_permnos |&gt; \n  select(ticker,permno) |&gt; \n  distinct()\n\n# A tibble: 3 × 2\n  ticker permno\n  &lt;chr&gt;   &lt;int&gt;\n1 SPY     33910\n2 SPY     60716\n3 SPY     84398\n\n\nNow there are only three observations,which is what I asked for, but sometimes it might matter which of the duplicate observations I keep. For example, perhaps what I should do is keep the most recent observation from the spy_permno dataset, in terms of nameenddt.\n\n#select the max data within each group as more advanced way to keep one obs per \n#group\nspy_permnos |&gt; \n  group_by(ticker,permno) |&gt;\n  filter(nameenddt==max(nameenddt))\n\n# A tibble: 3 × 16\n# Groups:   ticker, permno [3]\n  permno namedt     nameenddt  shrcd exchcd siccd ncusip   ticker comnam  shrcls\n   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt; \n1  33910 1962-07-02 1966-05-24    10      2  2893 &lt;NA&gt;     SPY    SPEEDR… A     \n2  60716 1978-10-03 1987-07-01    10      1  3811 84756710 SPY    SPECTR… &lt;NA&gt;  \n3  84398 2010-01-27 2024-12-31    73      4  6726 78462F10 SPY    SPDR S… &lt;NA&gt;  \n# ℹ 6 more variables: permco &lt;int&gt;, hexcd &lt;int&gt;, cusip &lt;chr&gt;, st_date &lt;date&gt;,\n#   end_date &lt;date&gt;, namedum &lt;dbl&gt;\n\n#ultimately we can assign the permno of the current observation, which we already know from manually checking is the correct permno, 84398\n\nspy_permno &lt;- spy_permnos |&gt; \n  group_by(ticker,permno) |&gt;\n  filter(nameenddt==max(nameenddt)) |&gt; \n  ungroup() |&gt; \n  filter(nameenddt==max(nameenddt)) |&gt; \n  select(permno) |&gt; \n  as.numeric()\n\nspy_permno\n\n[1] 84398\n\n\nNow we can use the SPY permno to pull monthly returns for SPY:\n\n# Pull CRSP MSI Data -----------------------------------------------------------\n\n#Data seems to begin in feb 1993, lets start in 1995 as a nice round number\n#notice that this implicitly feeds the permno I calculated locally back up to WRDS in my crsp query. \nmkt_index &lt;- crsp.msf |&gt; \n  filter(date &gt;= \"1995-01-01\",\n         permno == spy_permno) |&gt; \n  select(date,ret,prc) |&gt; \n  collect() |&gt; \n  mutate(month = month(date),\n         year = year(date))\n\nThen I can plot them, note that if you look at the source code for this page, I do this in a chunk with echo=false so that I only see the output and not the code. This would be useful for creating an actual paper rather than coding examples:\n\n\n\n\n\n\n\n\n\nThis plot would look nice with recessions shaded. We can get recession dates from FRED. FRED data can be accessed from an API, there is a custom package to work with FRED data in R called fredr. First you need to obtain a FRED API key by signing up here: https://fred.stlouisfed.org/docs/api/api_key.html\n\n#load the fredr package\nlibrary(fredr)\n\n#Unblock the below and run to set your password\n#keyring::key_set(\"fred_api_key\")\n\n#set my API key which is saved in keyring\nfredr_set_key(keyring::key_get(\"fred_api_key\"))\n\n#collect the data from the series USRECD\n# https://fred.stlouisfed.org/series/USRECD\n\nfred_data&lt;-fredr(series_id = \"USRECD\",\n                 observation_start = as.Date(\"1995-01-01\"),\n                 observation_end = as.Date(\"2024-12-31\"),\n                 frequency = \"m\") |&gt; \n  #I am going to add month and year variables because I think this is \n  #easier for linking\n  mutate(month = month(date),\n         year = year(date))\n\n# show the first few rows which has a value of 0 or 1 where 1 is recession\nfred_data |&gt; head() |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nseries_id\nvalue\nrealtime_start\nrealtime_end\nmonth\nyear\n\n\n\n\n1995-01-01\nUSRECD\n0\n2025-03-19\n2025-03-19\n1\n1995\n\n\n1995-02-01\nUSRECD\n0\n2025-03-19\n2025-03-19\n2\n1995\n\n\n1995-03-01\nUSRECD\n0\n2025-03-19\n2025-03-19\n3\n1995\n\n\n1995-04-01\nUSRECD\n0\n2025-03-19\n2025-03-19\n4\n1995\n\n\n1995-05-01\nUSRECD\n0\n2025-03-19\n2025-03-19\n5\n1995\n\n\n1995-06-01\nUSRECD\n0\n2025-03-19\n2025-03-19\n6\n1995\n\n\n\n\n\nNow we need to merge the SPY data with the recession data.\n\nmerged_data &lt;- mkt_index |&gt;\n  #I am going to select only the columns I need from   #the FRED data\n  inner_join(fred_data |&gt; \n               select(month,year,recession=value),\n             by=join_by(month,year))\n\n# check to make sure it is still unique by month \nmerged_data |&gt; \n  group_by(month,year) |&gt; \n  count() |&gt; \n  arrange(-n)\n\n# A tibble: 360 × 3\n# Groups:   month, year [360]\n   month  year     n\n   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n 1     1  1995     1\n 2     1  1996     1\n 3     1  1997     1\n 4     1  1998     1\n 5     1  1999     1\n 6     1  2000     1\n 7     1  2001     1\n 8     1  2002     1\n 9     1  2003     1\n10     1  2004     1\n# ℹ 350 more rows\n\n\nNow we can make the plot with shades for recession months\n\n#turns out the merged data was not the preferred way to do this kind of plot\n\n\n\n\n#here is some code I found online to reshape the recession data and add it to the plot \n\n#rename/assign fred data to recession because \n#that was the name in the example I found \nrecession&lt;-fred_data\n\n#load a package they used\nlibrary(ecm)\n\n#reshape the recession data for the way \n#geom_rect likes the data shaped\nrecession$diff&lt;-recession$value-lagpad(recession$value,k=1)\n  recession&lt;-recession[!is.na(recession$diff),]\n  recession.start&lt;-recession[recession$diff==1,]$date\n  recession.end&lt;-recession[recession$diff==(-1),]$date\n  \n  if(length(recession.start)&gt;length(recession.end))\n  {recession.end&lt;-c(recession.end,Sys.Date())}\n  if(length(recession.end)&gt;length(recession.start))\n  {recession.start&lt;-c(min(recession$date),recession.start)}\n  \n  recs&lt;-as.data.frame(cbind(recession.start,recession.end))\n  recs$recession.start&lt;-as.Date(as.numeric(recs$recession.start),origin=as.Date(\"1970-01-01\"))\n  recs$recession.end&lt;-as.Date(recs$recession.end,origin=as.Date(\"1970-01-01\"))\n\n#look at the reshaped data\nrecs \n\n  recession.start recession.end\n1      2001-04-01    2001-12-01\n2      2008-01-01    2009-07-01\n3      2020-03-01    2020-05-01\n\n#plot the new plot with recession bars\nmerged_data |&gt; \n  ggplot(aes(x=date,y=abs(prc))) + \n  geom_line() +\n  scale_x_date(name = \"Date\",\n               date_breaks= \"5 years\",\n               date_labels = \"%Y\") +\n  scale_y_continuous(name = \"SPY Closing Price\") +\n  geom_rect(data=recs, inherit.aes=F, \n                         aes(xmin=recession.start, xmax=recession.end, ymin=-Inf, ymax=+Inf), \n                fill=\"darkgrey\", alpha=0.5)+\n  theme_bw()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Obtaining and Merging Data</span>"
    ]
  },
  {
    "objectID": "merge-data.html",
    "href": "merge-data.html",
    "title": "4  Merging Data (In Progress)",
    "section": "",
    "text": "4.1 Common Sources of Firm-Level Data\nBelow is a table of common sources and firm identifiers that allow researchers to link data from different data sources:\nBlocking out for next attempt",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Merging Data (In Progress)</span>"
    ]
  },
  {
    "objectID": "merge-data.html#common-sources-of-firm-level-data",
    "href": "merge-data.html#common-sources-of-firm-level-data",
    "title": "4  Merging Data (In Progress)",
    "section": "",
    "text": "Data Source\nIdentifiers\nOther Firm Identifiers\nCan Be Linked To\nNotes\n\n\n\n\nCompustat\nGVKEY\nTicker, CIK\nCRSP, Audit Analytics\n\n\n\nCRSP\nPERMNO\nTicker, CUSIP\nCompustat, IBES\nTo link to Compustat data, researchers should use the CRSP-Compustat link file for PERMNO-GVKEY mapping.\n\n\nI/B/E/S\nTICKER\nOFTIC, CUSIP\nCRSP\nThe “TICKER” variable is the I/B/E/S firm identifier not the trading symbol. The trading symbol is the “OFTIC” variable.\n\n\nTAQ\nSYMBOL\n\n\n\n\n\nTRACE\nCUSIP\n\nCRSP\n\n\n\nAudit Analytics\nCIK\n\nCompustat\n\n\n\nXBRL\nCIK\n\nCompustat\n\n\n\nRavenPack\nRP_ENTITY_ID\nCUSIP\nCRSP, IBES",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Merging Data (In Progress)</span>"
    ]
  },
  {
    "objectID": "regression-table.html",
    "href": "regression-table.html",
    "title": "5  Regression Tables",
    "section": "",
    "text": "Test of embedding a regression in Quarto.\n\n\n\n\nTable 5.1\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Base\n                No FE\n                Year FE\n                Two-Way FE\n                With Controls\n              \n        \n        \n        \n                \n                  $ROA_{t}$\n                  0.839***\n                  0.756***\n                  0.769***\n                  0.639***\n                  0.624***\n                \n                \n                  \n                  (62.732)\n                  (48.155)\n                  (48.621)\n                  (38.634)\n                  (35.596)\n                \n                \n                  $LOSS$\n                  \n                  -0.030***\n                  -0.028***\n                  -0.015***\n                  -0.017***\n                \n                \n                  \n                  \n                  (-7.949)\n                  (-7.755)\n                  (-7.556)\n                  (-8.111)\n                \n                \n                  $ROA_{t} \\times LOSS$\n                  \n                  0.032\n                  0.012\n                  -0.285***\n                  -0.294***\n                \n                \n                  \n                  \n                  (1.470)\n                  (0.535)\n                  (-13.307)\n                  (-12.620)\n                \n                \n                  Year FE\n                  \n                  \n                  X\n                  X\n                  X\n                \n                \n                  Firm FE\n                  \n                  \n                  \n                  X\n                  X\n                \n                \n                  Controls\n                  \n                  \n                  \n                  \n                  X\n                \n                \n                  N\n                  163,298\n                  163,298\n                  163,298\n                  161,635\n                  161,635\n                \n                \n                  $R^2$\n                  0.594\n                  0.597\n                  0.603\n                  0.707\n                  0.707\n                \n                \n                  $R^2$ Within\n                  \n                  \n                  0.580\n                  0.184\n                  0.186",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regression Tables</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]